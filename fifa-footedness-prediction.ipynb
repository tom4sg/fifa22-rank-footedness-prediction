{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75520249-7e4b-46cf-8d06-0d785c5aaef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'shared/data/fifa22.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared/data/fifa22.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'shared/data/fifa22.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"shared/data/fifa22.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301af5d7-1e68-4734-8040-520638dd13b0",
   "metadata": {},
   "source": [
    "the unit of analysis appears to be an individual soccer players. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4df957-8186-4c0e-aa96-1d3b37dfc18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations, features = df.shape\n",
    "print(f\"Number of observations: {observations}\")\n",
    "print(f\"Number of features: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5885933-5e02-4dea-a96c-2c91504504c0",
   "metadata": {},
   "source": [
    "There are 19,630 observations and 20 features in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d4ebc-4c6e-4683-a04e-e4fd42246eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d8208-dc94-4c82-90ab-c5624c9af299",
   "metadata": {},
   "source": [
    "There are 19,239 male players and 391 female players in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82622b86-5410-48fe-a5de-d55cc0f4116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop only rows where the column passing contains a NaN for practice\n",
    "df_dropped = df.dropna(subset=['passing'])\n",
    "\n",
    "# display shape\n",
    "df_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a6556-275f-4159-814c-1b4458386cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6817a-d0f3-4d02-8796-2102c0a4100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['passing', 'attacking', 'defending', 'skill']]\n",
    "y = df['rank']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X, missing='drop').fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7214d960-49dd-4ae6-af70-f6d7e3245b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_values = model.fittedvalues\n",
    "residuals = model.resid\n",
    "\n",
    "plt.scatter(fitted_values, residuals)\n",
    "plt.title('Residual vs. Fitted Plot')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be96ad1-8efb-4816-8a1b-7d6d193e14e6",
   "metadata": {},
   "source": [
    "After plotting residual-versus-fitted, you can see that heteroskedasticity is not a problem because the plot does not have a clear trend. \n",
    "One concern could be the outlier values that have residuals between the 15-20 range(roughly x=65). Since residual is the difference/error between the predicted and observed values, outliers with unusually large residuals could mean that the model's accuracy is inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf997c-6e2b-4edd-9989-e78272197225",
   "metadata": {},
   "source": [
    "The variation in rank which is explained by our features is the R-squared statistic, which is 0.705. We can say that about 70.5% of the variation in rank is explained by the features in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a5341-558d-424b-b756-37dede313881",
   "metadata": {},
   "source": [
    "Holding passing, attacking, and defending constant, a 1-unit increase in “skill” is associated with a .0066 increase in rank. I got this value by observing the coefficient associated with skill in the model summary. Notice still that the p-value for skill .465, meaning that it might not have a big influence here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bac087-0141-4662-92d7-63a5641d4927",
   "metadata": {},
   "source": [
    "A 95% confidence interval for the effect of a 1-unit increase in skill(holding passing, attacking, and defending constant) on ranking is [-0.011, 0.024], as seen in the model summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef12b364-21b5-4d8d-97f2-9934e683b94d",
   "metadata": {},
   "source": [
    "Since the 95% confidence interval for the effect of a 1-unit increase in skill (holding other features constant) on ranking is [-0.011, 0.024], we can glean several things. Firstly, if we were to repeatedly collect random samples from the population and calculate the confidence interval for the coefficient associated with the skill feature, then in 95% of those samples, the true coefficient would fall within the calculated confidence interval. Secondly, the 95% confidence interval contains zero, meaning that a 1-unit increase in skill (holding other features constant) could correspond to a negative effect, a positive effect, or no effect at all. This inclusion of zero suggests that the null hypothesis—that the coefficient of skill is zero—cannot be rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be9111-fe2a-4321-b5d4-d3436ac09601",
   "metadata": {},
   "source": [
    "Based on the OLS regression, we can expect that the four features (passing, attacking, defending, and skill) will do fairly well for predicting rank for out-of-sample data based on a few things. Firstly, the R-squared value is 0.705, meaning that 70.5% of the variance in the rank is explain by the four features previously mentioned. Secondly, if we choose an alpha level of .05, we can say that passing, attacking, and defending are statistically significant predictors of rank. However, skill has a p-value of 0.465, indicating it is not statistically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf3a9ee-af8d-4dfb-8f6f-3c7218cbc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c2543-eab4-4cbe-b988-c12b343e27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an X dataframe with just four features: passing, attacking, defending, and skill\n",
    "X = df[['passing', 'attacking', 'defending', 'skill']]\n",
    "# Create a Y dataframe (or series) with just the “rank” variable\n",
    "Y = df['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c1582-88f1-4878-858a-413095626cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X first five rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9ad29-8dfe-4825-a114-05101340a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y first five rows\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6888c-b3f9-440a-928a-d1d0f3d7908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=123)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f6e5e-fe96-44e8-8ea6-cc7dde7ccdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X_train_clean = X_train.dropna()\n",
    "Y_train_clean = Y_train.loc[X_train_clean.index]\n",
    "\n",
    "# Train a linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_clean, Y_train_clean)\n",
    "\n",
    "# Get intercept and coefs\n",
    "intercept = linear_model.intercept_\n",
    "coefficients = linear_model.coef_\n",
    "\n",
    "intercept, coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2089c0e-a6c3-4daf-800a-c5b8cbc95ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get difference between Attacking coefficients from both models\n",
    "statsmodels_coef = 0.6109\n",
    "sklearn_coef = coefficients[1]\n",
    "print(f\"Difference between Attacking coefficient: {statsmodels_coef - sklearn_coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83848878-1f1c-465b-8bc7-87110fa166be",
   "metadata": {},
   "source": [
    "The coefficients are pretty similar. In the OLS regression model, the coefficients were the following - Passing: -0.0247, Attacking: 0.6109, Defending: 0.1719, Skill: 0.0066. The linear regression (SKLearn) done in part has the following coefficients - Passing: -0.02738345, Attacking: 0.61570071, Defending: 0.17364093, Skill: 0.00464593. Notice that the \"Attacking\" coefficient decreased by roughly -0.004800 (as you can see above) from the statsmodels regression to the SKLearn one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e677aa9-3b0d-4f84-b31b-ec97040d4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use linear_model to predict X validation set data\n",
    "Y_val_predictions = linear_model.predict(X_val.dropna())\n",
    "\n",
    "# Display the first three predicted values\n",
    "Y_val_predictions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9457ce-43bc-42d0-9a37-e6cdb639a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_clean = Y_val.loc[X_val.dropna().index]\n",
    "# Scatterplot of actual vs predicted Y values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Y_val_clean, Y_val_predictions)\n",
    "# Plot x = y to compare with observed vs. predicted\n",
    "plt.plot([Y_val_clean.min(), Y_val_clean.max()], [Y_val_clean.min(), Y_val_clean.max()], color='red') \n",
    "plt.title(\"Actual vs Predicted Y Values\")\n",
    "plt.xlabel(\"Actual Y Values (Validation Data)\")\n",
    "plt.ylabel(\"Predicted Y Values\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea6697-93e8-4532-bbfa-53d0576db5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "rmse = np.sqrt(mean_squared_error(Y_val_clean, Y_val_predictions))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e50e18-5720-4f77-933a-86ed44ce9cd3",
   "metadata": {},
   "source": [
    "As you can see by the calculation above, the Root Mean Squared Error is around 3.7308. This means that the average error across the model between the predicted Y-values and the actual observed Y-values is roughly 3.7308 units. Based on this, the model seems to provide fairly accurate predictions although there is still room for improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c8a9f-352e-4468-ab5b-198ca9d34731",
   "metadata": {},
   "source": [
    "As mentioned above, I think this model provides fairly accurate predictions for player rank. The RMSE is around 3.7308, meaning that the average error between predicted Y-values and observed ones is approximately 3.7308 rank units. The scatterplot of predicted vs. observed Y-values shows that predictions generally align well with the x=y line, suggesting that the model captures the underlying pattern nicely. While there are some outliers, the model performs well overall in predicting player rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1dc59f-2164-426b-a092-14e44f804d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preferred_foot'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427407a-502f-43f3-8baf-efdde415d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_foot_percentage = (df['preferred_foot'].value_counts()['Right'] / df.shape[0]) * 100\n",
    "print(f\"% of right-footed players: {round(right_foot_percentage, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcad5ec-68b0-4a5b-8638-08fc98fc021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_classifier = df[['shooting', 'passing', 'dribbling', 'defending', 'attacking', \n",
    "                          'skill', 'movement', 'power', 'mentality', 'goalkeeping']]\n",
    "X_classifier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac80c64-bed6-4f26-b4d4-ee43d17bd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X_classifier)\n",
    "X_normalized_df = pd.DataFrame(X_normalized, columns=X_classifier.columns)\n",
    "\n",
    "# Display first three rows of the normalized data\n",
    "X_normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44c963-670e-44b4-9a42-9b25b4e5b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_classifier = df['preferred_foot']\n",
    "X_train_classifier, X_val_classifier, Y_train_classifier, Y_val_classifier = train_test_split(\n",
    "    X_normalized_df, Y_classifier, test_size=0.30, random_state=456)\n",
    "\n",
    "# Display first 5 rows of X training data\n",
    "X_train_classifier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303ea83-f148-4480-9a48-a07c533d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Although maybe not entirely necessary, lets impute missing values rather than dropping rows that contain them. \n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_classifier_imputed = imputer.fit_transform(X_train_classifier)\n",
    "X_val_classifier_imputed = imputer.transform(X_val_classifier)\n",
    "# Initialize list for k_values and accuracies - will append accuracies list later\n",
    "k_values = list(range(1, 31))\n",
    "accuracies = []\n",
    "# for loop through list and calculate accuracy\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_classifier_imputed, Y_train_classifier)\n",
    "    # Predict on the validation set\n",
    "    Y_val_pred = knn.predict(X_val_classifier_imputed)\n",
    "    accuracy = accuracy_score(Y_val_classifier, Y_val_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# adjust figsize, if not x-axis numbers are squashed\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, accuracies, marker='o')\n",
    "plt.title('KNN Classifier Accuracy vs. Number of Neighbors (k)')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb16ef75-edd3-4f76-9eb6-6b61fd121b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best value for K: {k_values[accuracies.index(max(accuracies))]}\")\n",
    "print(f\"Accuracy for K-value 29: {round(max(accuracies), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95834ec1-2590-44aa-850d-e2f190d0193e",
   "metadata": {},
   "source": [
    "As you can see above, the most reasonable k-value is 29, because it has the highest accuracy with roughly .7709 when rounded to the nearest 4th decimal place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f5f5d-c839-4f91-81fb-3c45d5e47ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_final = KNeighborsClassifier(n_neighbors=29)\n",
    "knn_final.fit(X_train_classifier_imputed, Y_train_classifier)\n",
    "Y_val_final_pred = knn_final.predict(X_val_classifier_imputed)\n",
    "# Display (at least) the first 3 predictions for “preferred foot.”\n",
    "Y_val_final_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba9e86-4808-4f37-9aa2-93891ed41ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(Y_val_classifier, Y_val_final_pred)\n",
    "# Extract num for True Lefts predicted as Right\n",
    "true_left_pred_right = conf_matrix[0, 1]\n",
    "true_left_pred_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4367f-cd77-4846-aa55-f13eaca09e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(Y_val_classifier, Y_val_final_pred)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a5afe-6c94-41fb-8c6c-7204b8b9301f",
   "metadata": {},
   "source": [
    "The recall here (.05) suggests that the model only correctly identified 5% of the true left-footers in the dataset. One must always be careful when classes are very unbalanced. We previously saw that the soccer players in this study disproportionately skew to be right-footed, meaning our KNN model trained on this data set could be biased towards predicting right-footers. Notice how the recall for right-footed predictions is unbelievably high, around 99%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33270b-650f-4ee4-8325-d1f54ff57857",
   "metadata": {},
   "source": [
    "Overall, the model does a poor job of predicting a player's preferred foot. As we calculated early on, simply guessing that a player is right-footed each time would yield an accuracy of 76.34%, which is already quite high. After optimizing k for KNN, the model achieved only a marginal improvement, with an accuracy of 77.09%. While this may seem satisfactory at first, the recall for left-footers was shockingly low. The model predicts right-footers well, but this is largely because it guesses 'Right' most of the time due to the class imbalance. Accuracy alone is not a sufficient metric for evaluating models in the presence of unbalanced classes. The model's inability to predict left-footed players makes it inadequate for predicting a players preferred-foot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
